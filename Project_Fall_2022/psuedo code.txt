

Psuedo Code:


CNN Convolution:

for(int i=0;i<N-2;i++){
   for(int j=0;j<N-2;j++){
      for(int a=0; a<=2;a++){
	    for(int b=0;b<=2;b++){
		  x[i][j]= kernel[a][b]+InputMatrix[i+a][j+b]
		}
      }
   	}
}

ReLu Funtion:

for(int i=0;i<N-2;i++){
   for(int j=0;j<N-2;j++){
      if(x[i][j]>0){
	     x[i][j]=x[i][j];
	  }	 
	  else{
	     x[i][j]=0;                   
	  }
   }
}

MaxPoole Function:

for(int i=0;i< (N-2/2);i++){
   for(int j=0;j<(N-2/2);j++){
      int y= max(x[i][j], x[i+1][j]);
	  int z= max(x[i][j+1], x[i+1][j+1]);
	  maxPool[i][j]= max(y,z);
   }
}

Fully Connected Layers of Neural networks:

for(int i=0;i<N-2/2;i++){
   for(int j=0;j<1;j++){
     for(int k=0;k<N-2/2;k++){
      out[i][j]+=out[i][j]+ maxPool[i][k]*weight[k][j];
	 }
   }
}

Activation Function:
for(int i=0;i<N-2/2;i++){
   for(int j=0;j<1;j++){
      output[i][j]= fn(out[i][j]);
   }
}
